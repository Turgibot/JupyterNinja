{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 1 - Introduction to Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Model with TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created by [Guy Tordjman](https://github.com/Turgibot). Based on the [Tensorflow official tutorials](https://www.tensorflow.org/tutorials/) and [Hvass Laboratories](http://www.hvass-labs.org/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About this lesson:\n",
    "<p style=\"font-size:16px;\">\n",
    "prerequisites:<br>\n",
    "To enjoy the most of this lesson one should be familiar with the python programming language, basic linear algebra like matrix multiplication, gradient descent and the jupyter notebook interface. \n",
    "Any knowledge of machine learning and classification is helpful but not required for the purpose of this lesson.\n",
    "At the end of this lesson you'll be able to classify images of digits and more important you'll understand a basic tensorflow workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why TensorFlow?\n",
    "<p style=\"font-size:16px;\">\n",
    "    TensorFlow was originally created by researchers at Google as a single infrastructure for machine learning in both production and research. On the Tensorflow website, we see:<br><br>\n",
    "   “TensorFlow™ is an open source software library for\n",
    "    numerical computation using data flow graphs.”<br><br>\n",
    "    TensorFlow is both flexible and scalable, allowing users to streamline from research into production.\n",
    "<br>\n",
    "This unique position allowed TensorFlow to grow quickly. It’s currently being used by big companies such as Google, OpenAI, NVIDIA, Intel, SAP, eBay, Airbus, Uber, Airbnb, Snap, Dropbox and startups alike. By the number of stars and related repositories on GitHub as of Jan 11, 2018, TensorFlow is by far the most popular machine learning library with more than 85.4k stars and 25.3k related repositories, twice as much as the total stars and related repositories of Caffe, PyTorch, Torch, and Theano combined. \n",
    "<br>\n",
    "In summary, we chose TensorFlow because:\n",
    "\n",
    "<ul style=\"font-size:16px;\">\n",
    "    <li>Python API</li>\n",
    "<li>Portability: deploy computation to one or more CPUs or GPUs in a desktop, server, or mobile device with a single API</li>\n",
    "<li>Flexibility: from Raspberry Pi, Android, Windows, iOS, Linux to server farms</li>\n",
    "<li>Visualization (Lesson >=3 using 'TensorBoard')</li>\n",
    "<li>Save and restore models, graphs</li>\n",
    "<li>Auto-differentiation autodiff</li>\n",
    "<li>Large community (~300k commits, ~85k repositories)</li>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.contrib.learn.python.learn.datasets.mnist import read_data_sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF version should be bigger than 1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.7.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data \n",
    "<p style=\"font-size:16px;\">\n",
    "Downloading the 12MB data-set to a specific path \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mnist\n",
    "train_images = mnist.train_images()\n",
    "train_labels = mnist.train_labels()\n",
    "test_images = mnist.test_images()\n",
    "test_labels = mnist.test_labels()\n",
    "eval_images = train_images[:5000]\n",
    "eval_labels = train_labels[:5000]\n",
    "train_images = train_images[5000:]\n",
    "train_labels = train_labels[5000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the size of the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training-set:\t55000\n",
      "Test-set:\t10000\n",
      "Evaluation-set:\t5000\n"
     ]
    }
   ],
   "source": [
    "train_len = len(train_labels)\n",
    "test_len = len(test_labels)\n",
    "eval_len = len(eval_labels)\n",
    "print('Training-set:\\t{}'.format(train_len))\n",
    "print('Test-set:\\t{}'.format(test_len))\n",
    "print('Evaluation-set:\\t{}'.format(eval_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets arrange the data in a dictionary data structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set One Hot Encoding\n",
    "<p style=\"font-size:16px;\">\n",
    "    Our labels are simply the number which is represented in the image. <br>Here are the first 5 labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, 0, 4], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:16px;\"> In one hot representation the number represents the index which value is 1 where the rest are 0's.\n",
    "We are classifying 10 digits (0 - 9), therefor a vector og length=10 is needed to represent each label.\n",
    "For example the label where the digit is 7 is represented by: '[0,0,0,0,0,0,0,1,0,0]'.\n",
    "Lets create a function that converts to one hot.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_one_hot(vector, num_classes):\n",
    "    result = np.zeros(shape=(len(vector), num_classes))\n",
    "    result[np.arange(len(vector)), vector] = 1\n",
    "    return result.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "test_labels_oh = convert_to_one_hot(test_labels, num_classes)\n",
    "train_labels_oh = convert_to_one_hot(train_labels, num_classes)\n",
    "eval_labels_oh = convert_to_one_hot(eval_labels, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels_oh[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we converted all the labels in our data set to one hot.<br>\n",
    "Now, lets organize it in a class object data structure\n",
    "Before we should flatten the 28 * 28 images to a 1 dimention 784 long vector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Input:\n",
    "    \n",
    "    def __init__(self, images, labels, classes):\n",
    "        self.data_set_size = len(labels)\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.classes = classes\n",
    "        self.processed = 0\n",
    "        self.epoch_done = False\n",
    "    \n",
    "    def next_batch(self,batch_size):\n",
    "        start = self.processed\n",
    "        end = start+batch_size\n",
    "        if end >= self.data_set_size:\n",
    "            end = self.data_set_size-1\n",
    "            self.epoch_done = True\n",
    "        self.processed = end\n",
    "        img_batch = self.images[start:end]\n",
    "        label_batch = self.labels[start:end]\n",
    "        classes_batch = self.classes[start:end]\n",
    "        \n",
    "        if self.epoc_done is True:\n",
    "            self.processed = 0\n",
    "            self.epoch_done = False\n",
    "        \n",
    "        return img_batch, label_batch, classes_batch\n",
    "            \n",
    "        \n",
    "    \n",
    "class Data:\n",
    "    #reshape the images\n",
    "    train_images_rs = np.reshape(train_images, (55000, 784))\n",
    "    test_images_rs =  np.reshape(test_images, (10000, 784))\n",
    "    eval_images_rs = np.reshape(eval_images, (5000, 784))\n",
    "    \n",
    "    train = Input(train_images_rs,train_labels_oh,train_labels)\n",
    "    test = Input(test_images_rs,test_labels_oh,test_labels)\n",
    "    evaluation = Input(eval_images_rs,eval_labels_oh,eval_labels)\n",
    "\n",
    "data = Data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get The Image Data\n",
    "<p style=\"font-size:16px;\">\n",
    "    For future calculations we would need to know the dimentions of the image we work with.<br>\n",
    "    our list contains of 10000 images and each it a 3d matrix (2d - in black n white images like MNIST) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image shape is: (28, 28)\n"
     ]
    }
   ],
   "source": [
    "single_image = train_images[0]\n",
    "img_shape = single_image.shape\n",
    "image_flat_size = img_shape[0]*img_shape[1]\n",
    "print('The image shape is: {}'.format(img_shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the Images\n",
    "<p style=\"font-size:16px;\">\n",
    "    Create a helper function that display a 4X8 grid of images with the classification results noted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images_grid(images, img_shape, given_class, predicted_class=None):\n",
    "    assert len(images) == 32\n",
    "    assert len(given_class) == 32\n",
    "    \n",
    "    fig, axes = plt.subplots(4, 8)\n",
    "    fig.subplots_adjust(hspace=0.5, wspace=0.05, left=0, right=2.3)\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        # Plot each image\n",
    "        ax.imshow(images[i].reshape(img_shape), cmap='binary')\n",
    "\n",
    "        # Show given and predicted classes if exists.\n",
    "        if predicted_class is None:\n",
    "            xlabel = \"Class: {0}\".format(given_class[i])\n",
    "            ax.set_xlabel(xlabel)\n",
    "                \n",
    "        else:\n",
    "            xlabel = \"Class: {0}, Predicted: {1}\".format(given_class[i], predicted_class[i])\n",
    "            if given_class[i] == predicted_class[i]:\n",
    "                ax.set_xlabel(xlabel, color='green')\n",
    "            else:\n",
    "                ax.set_xlabel(xlabel)\n",
    "                ax.set_xlabel(xlabel, color='red')\n",
    "                \n",
    "\n",
    "        \n",
    "        \n",
    "        # Remove ticks from the plot.\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        \n",
    "    # Ensure the plot is shown correctly with multiple plots\n",
    "    # in a single Notebook cell.\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 32 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_images = data.train.images[0:32]\n",
    "classes = data.train.classes[0:32]\n",
    "plot_images_grid(sample_images, img_shape, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF.Graph\n",
    "<p style=\"font-size:16px;\">\n",
    "    A graph consists of nodes and edges that represent the computation procedure. To simplify things for now we'll agree that Tensor flow uses a computational graph that is executed much more efficiently than if the same calculations were to be performed directly in Python. <br>\n",
    "   Next, we shell construct the graph and explain in details about each part below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Place Holder Variable\n",
    "<p style=\"font-size:16px;\">\n",
    "    A placeholder is a type of variable which purpose is exactly as it's name suggests - to hold a place for an input. One can look at it as a promise of the developer to feed data into this the graph when time comes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, image_flat_size])\n",
    "y_given = tf.placeholder(tf.float32, [None, num_classes])\n",
    "y_given_class = tf.placeholder(tf.int64, [None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:16px;\">\n",
    "    When printed we can see information about the placeholder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Placeholder_1:0' shape=(?, 10) dtype=float32>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Placeholder_2:0' shape=(?,) dtype=int64>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_given_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:16px;\">\n",
    "    <strong>x</strong> is the placeholder variable for the input images. It is a tensor which means a multi-dimensional vector or matrix.  The data-type is set to float32 and the shape is set to [None, image_flat_size], where None means that the tensor may hold any number of images with each image being a vector of length image_flat_size(28*28=784 in our case)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:16px;\">\n",
    "    <strong>y_given</strong> is the placeholder variable for the given labels of the input images in the placeholder variable x. The shape of this placeholder variable is [None, num_classes] which means it may hold any number of labels and each label is a vector of length num_classes (10)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:16px;\">\n",
    "    <strong>y_given_class</strong> is the placeholder variable for the actual class of each image in the placeholder variable x. These are integers and the dimensionality of this placeholder variable is set to [None] which means the placeholder variable is a one-dimensional vector of any length."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tf.Varable - Weights and Biases\n",
    "<p style=\"font-size:16px;\">\n",
    "As mentioned - the purpose of placeholder are to feed input data into the graph. Other than input and output there are other variables that need to be calculated and changed and optimized when running the program. These are called tf.Variables. <br>\n",
    "    TensorFlow recommends that we use the wrapper tf.get_variable, which allows for easy variable sharing. With tf.get_variable, we can provide variable’s internal name, shape, type, and initializer to give the variable its initial value.\n",
    "    <br><br>\n",
    "    tf.get_variable(<br>\n",
    "    name,<br>\n",
    "    shape=None,<br>\n",
    "    dtype=None,<br>\n",
    "    initializer=None,<br>\n",
    "    regularizer=None,<br>\n",
    "    trainable=True,<br>\n",
    "    collections=None,<br>\n",
    "    caching_device=None,<br>\n",
    "    partitioner=None,<br>\n",
    "    validate_shape=True,<br>\n",
    "    use_resource=None,<br>\n",
    "    custom_getter=None,<br>\n",
    "    constraint=None<br>\n",
    ")<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = tf.get_variable('weights', initializer=tf.zeros([image_flat_size, num_classes]))\n",
    "biases = tf.get_variable('biases', initializer=tf.zeros([num_classes]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:16px;\">\n",
    "    <strong>weights</strong> is a TensorFlow variable and is initialized with zeros. It's shape is [image_flat_size, num_classes], a 2-dimensional matrix with 784 (image_flat_size) rows and 10 (num_classes) columns.<br><br>\n",
    "    We can see this info by priniting it in browser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'weights:0' shape=(784, 10) dtype=float32_ref>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:16px;\">\n",
    "    <strong>biases</strong> is a vector of length num_classes\n",
    "    We can also see this info by priniting it in browser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'biases:0' shape=(10,) dtype=float32_ref>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mathematical Model\n",
    "<p style=\"font-size:16px;\">\n",
    "    Now that we have our placeholders (for input) and our variables defined we can do something with them - we can build a model.\n",
    "   This is the first lesson so the model is very basic.<br>\n",
    "    It multiplies the images in the placeholder variable x with the weights and then adds the biases.\n",
    "    It then stores the the result in a matrix typically named logits:  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_logits = tf.matmul(x, weights) + biases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:16px;\">\n",
    "x has a shape of( train_len, image_flat_size) -> (5500, 784)<br>\n",
    "weights has a shape of (image_flat_size, num_classes) -> (784, 10)<br>\n",
    "so the result is of shape (train_len, num_classes) -> (5500, 10) <br>\n",
    "    That means that each image of the 5500 links to a vector with 10 posibilities...\n",
    "    <br>\n",
    "    Remember the promise we made? we should store the result in the \"y_predicted\" placeholder.\n",
    "    but before lets normalize the results so each vector of 10 options will sum to 1 so each element's value is limited between 0 and 1. For that we use the softmax function. We will learn in more details about this function in a future lesson. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = tf.nn.softmax(y_logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:16px;\">\n",
    "The neuron that has the maximum value is the predicted class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted_class = tf.argmax(y_predicted, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Cost Function and Optimization\n",
    "<p style=\"font-size:16px;\">\n",
    "Chances are that when we try to classify an image using the existing weights and biases - we'll get a wrong result. We all learn by making mistakes and correct our doing so why shouldn't our program learn from it's mistakes and improve by correct itself?<br>\n",
    "First we've got to see how wrong we are, and for that we have a cost function.\n",
    "    \n",
    "## The cost function\n",
    "<p style=\"font-size:16px;\">\n",
    "The cost function is a function that mainly answers the question: \"How far are we from the truthful value?\"\n",
    "There is a number of cost functions that one can use and some work better than other on certain models. I'll cover other cost function in future lesson. \n",
    "Because this is an introductory lesson I'll not go deep into the math of the cost function that we'll use. Understanding the higher level should suffice for the time being.<br>\n",
    "\n",
    "### The Cross Entropy\n",
    "<p style=\"font-size:16px;\">\n",
    "A desired cost function should return a zero if we got the right class - if we got it wrong we want a scaled value that will tell us how wrong we are - how exponentially wrong we are might work?<br>\n",
    "The cross-entropy does it for us. It is always positive and continuous and if the predicted output of the model exactly matches the desired output then the cross-entropy equals zero.<br>\n",
    "\n",
    "### Optimize it!!\n",
    "<p style=\"font-size:16px;\">\n",
    "AS mentioned cost = 0 tells us that we are classifying the images correctly. Therefor one should seek to minimize the cross-entropy by changing the weights and biases of the model - this is called optimization.\n",
    "TensorFlow has a built-in function for calculating the cross-entropy. Note that it uses the values of the logits because it also calculates the softmax internally.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=y_logits,\n",
    "                                                        labels=y_given)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:16px;\">\n",
    "The cross entropy is a vector with the same shape of the input. We need a scalar number that represents the cost of intire model. So we'll simply average it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Mean:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Optimizer\n",
    "<p style=\"font-size:16px;\">\n",
    "Lets define our optimizer. We are actually adding another node to the graph telling it to minimize the cost by using a certain method for optimization. In our case it is the basic form of Gradient Descent where the step-size is set to 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.5).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How close are we?\n",
    "<p style=\"font-size:16px;\">\n",
    "We need to measure our progress.<br>\n",
    "The cost function tells us how far we are from perfectness. But we would like to know exactly how acurate our model is?\n",
    "    to find out if we are correct or not for each image we can simply run this code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "correctness = tf.equal(y_predicted_class , y_given_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "correctness = tf.cast(correctness, tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:16px;\">\n",
    "Basically its a long vector where each correct label is represented by 1 and a wrong one by 0 \n",
    "    \n",
    "## Accuracy\n",
    "<p style=\"font-size:16px;\">\n",
    "    is the average of our correctness vector. Note that casting to float was neccessary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(correctness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run It!!\n",
    "So far we did not calculate anything , we just constructed the graph, preparing it for later execution.\n",
    "To do so we have to create a TensorFlow session.\n",
    "\n",
    "## tf.Session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:16px;\">\n",
    "Remember to initialize all our variables. Thats why we defined a type of initializer when we created them.\n",
    "Any action that we want to conduct in the graph must be stated inside of a session.run() function.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## batching\n",
    "<p style=\"font-size:16px;\">\n",
    "Calculating the changes in the weights and biases after every image is very source consuming and slow. Instead with TF we can use Stochastic Gradient Descent which only uses a batch of images in each iteration of the optimizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:16px;\">\n",
    "Lets create a function for optimizing our training model. \n",
    "first lets get familiar with a new term: \"epoch\" .One epoch consists of one full training cycle on the training set. Once every sample in the set is seen, you start again - marking the beginning of the 2nd epoch. \n",
    "It takes in as parameters the number of epochs and the batch size:\n",
    "Remember: there are many batches in a single epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_by_batch(num_iterations, batch_size):\n",
    "    for i in range(num_iterations):\n",
    "        # get the next batch of images and labels\n",
    "        x_image_batch, y_given_batch, y_given_class = data.train.next_batch(batch_size)\n",
    "        \n",
    "        # create a dictionary of the placeholders.\n",
    "        feed_dict_train = {x: x_image_batch,\n",
    "                           y_given: y_given_batch}\n",
    "\n",
    "        # Run the optimizer \n",
    "        session.run(optimizer, feed_dict=feed_dict_train)\n",
    "        print('batch {0} / {1}'.format(i+1, num_iterations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_by_epochs(num_epochs, batch_size):\n",
    "    data.train.processed = 0\n",
    "    batch_num = int(data.train.data_set_size / batch_size)\n",
    "    for i in range(num_epochs):\n",
    "        for j in range(batch_num):\n",
    "            # get the next batch of images and labels\n",
    "            x_image_batch, y_given_batch, y_given_class = data.train.next_batch(batch_size)\n",
    "\n",
    "            # create a dictionary of the placeholders.\n",
    "            feed_dict_train = {x: x_image_batch,\n",
    "                               y_given: y_given_batch}\n",
    "\n",
    "            # Run the optimizer \n",
    "            session.run(optimizer, feed_dict=feed_dict_train)\n",
    "        print('epoch {0} / {1}'.format(i+1, num_epochs))        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:16px;\">\n",
    "Create a feed dictionary to hold all the test dataset input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_dict_test = {x:data.test.images,\n",
    "                  y_given: data.test.labels,\n",
    "                  y_given_class: data.test.classes}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <p style=\"font-size:16px;\">\n",
    "Create a function to Get the Accracy value and print it to screen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_and_print_accuracy():\n",
    "    session_accuracy = session.run(accuracy, feed_dict=feed_dict_test)\n",
    "    \n",
    "    # Print the accuracy.\n",
    "    print(\"Accuracy on test-set: {0:.1%}\".format(session_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Blas GEMM launch failed : a.shape=(10000, 784), b.shape=(784, 10), m=10000, n=10, k=784\n\t [[Node: MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](_arg_Placeholder_0_0/_1, weights/read)]]\n\t [[Node: Mean_1/_5 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_23_Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'MatMul', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 112, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 760, in _run_callback\n    ret = callback()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 536, in <lambda>\n    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-20-d4d7a535cae3>\", line 1, in <module>\n    y_logits = tf.matmul(x, weights) + biases\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py\", line 2108, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 4209, in mat_mul\n    name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 3290, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1654, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInternalError (see above for traceback): Blas GEMM launch failed : a.shape=(10000, 784), b.shape=(784, 10), m=10000, n=10, k=784\n\t [[Node: MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](_arg_Placeholder_0_0/_1, weights/read)]]\n\t [[Node: Mean_1/_5 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_23_Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1312\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    517\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Blas GEMM launch failed : a.shape=(10000, 784), b.shape=(784, 10), m=10000, n=10, k=784\n\t [[Node: MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](_arg_Placeholder_0_0/_1, weights/read)]]\n\t [[Node: Mean_1/_5 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_23_Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-9545d1e4c915>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcalculate_and_print_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-36-f777186cff0b>\u001b[0m in \u001b[0;36mcalculate_and_print_accuracy\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcalculate_and_print_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0msession_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Print the accuracy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy on test-set: {0:.1%}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Blas GEMM launch failed : a.shape=(10000, 784), b.shape=(784, 10), m=10000, n=10, k=784\n\t [[Node: MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](_arg_Placeholder_0_0/_1, weights/read)]]\n\t [[Node: Mean_1/_5 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_23_Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'MatMul', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 112, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 760, in _run_callback\n    ret = callback()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 536, in <lambda>\n    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-20-d4d7a535cae3>\", line 1, in <module>\n    y_logits = tf.matmul(x, weights) + biases\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py\", line 2108, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 4209, in mat_mul\n    name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 3290, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1654, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInternalError (see above for traceback): Blas GEMM launch failed : a.shape=(10000, 784), b.shape=(784, 10), m=10000, n=10, k=784\n\t [[Node: MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](_arg_Placeholder_0_0/_1, weights/read)]]\n\t [[Node: Mean_1/_5 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_23_Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "calculate_and_print_accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <p style=\"font-size:16px;\">\n",
    "As you can see before training the model our chances to predict the image class is less than 10%.\n",
    "lets plot it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_images = data.test.images[0:32]\n",
    "classes = data.test.classes[0:32]\n",
    "classes_pred = session.run(y_predicted_class, feed_dict=feed_dict_test)\n",
    "plot_images_grid(sample_images, img_shape, classes, classes_pred[0:32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize_by_batch(num_iterations=3, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:16px;\">\n",
    "This are the results after 3 iterations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_and_print_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "classes_pred = session.run(y_predicted_class, feed_dict=feed_dict_test)\n",
    "plot_images_grid(sample_images, img_shape, classes, classes_pred[0:32])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:16px;\">\n",
    "    After a very short training our weights and biases got tuned to classify a few images. Amazing don't you think? <br>\n",
    "    How does the weight look like? lets create a function to plot some weights and run it: \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_weights():\n",
    "    # Get the weights.\n",
    "    w = session.run(weights)\n",
    "    \n",
    "    # Get the min and max values \n",
    "    w_min = np.min(w)\n",
    "    w_max = np.max(w)\n",
    "\n",
    "    # Create figure with 3x4 sub-plots,\n",
    "    # where the last 2 sub-plots are unused.\n",
    "    fig, axes = plt.subplots(2, 5)\n",
    "    fig.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        if i<10:\n",
    "            image = w[:, i].reshape(img_shape)\n",
    "            ax.set_xlabel(\"Weights: {0}\".format(i))\n",
    "\n",
    "            # Plot the image.\n",
    "            ax.imshow(image, vmin=w_min, vmax=w_max, cmap='seismic')\n",
    "\n",
    "        # Remove ticks from each sub-plot.\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('number of processed images is {}'.format(data.train.processed))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize_by_epochs(num_epochs=5, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_and_print_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct, classes_pred = session.run([correctness, y_predicted_class], feed_dict=feed_dict_test)\n",
    "plot_images_grid(sample_images, img_shape, classes, classes_pred[0:32])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:16px;\">\n",
    "We've completed our first mission and got a clssifier with an accuracy percentage of more than 85% with a basic linear classifier. Think about twicks and changes to the code that can improve this accuracy. We've learned alot - good job. Time for the second lesson now...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## License (MIT)\n",
    "\n",
    "Copyright (c) 2018 by [Guy Tordjman](https://github.com/Turgibot)\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
